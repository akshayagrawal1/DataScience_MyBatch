{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chatbot-countvectorizer-cosine.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"GYLsj_SHyoPj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"259383ab-fbc1-4a2c-ffc8-6b0e4eed19c6","executionInfo":{"status":"ok","timestamp":1552795080226,"user_tz":-330,"elapsed":63005,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/drive/')\n","import os\n","os.chdir('/drive/My Drive/SKRA/NLP')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive/\n"],"name":"stdout"}]},{"metadata":{"id":"aImQZjRJyvox","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","os.chdir('/drive/My Drive/SKRA/NLP')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0-Lp2kX0zXXE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"43e3cc56-2b95-4fef-9861-c814d586fb23","executionInfo":{"status":"ok","timestamp":1552795245481,"user_tz":-330,"elapsed":4781,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["chatbot-countvectorizer-cosine.ipynb  chat_bot.csv  TextRanking.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"C_XFP1qszwih","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"1aa4d6d2-6b1d-4edc-9026-56e4ff3c1158","executionInfo":{"status":"ok","timestamp":1552795847542,"user_tz":-330,"elapsed":1674,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk import word_tokenize, sent_tokenize # tokenization\n","from nltk.stem import WordNetLemmatizer # Lemmatization\n","from nltk import pos_tag # pos tagging\n","#from nltk.stem import PorterStemmer # stemming\n","from nltk.corpus import wordnet # wordnet\n","import re # regular expression\n","from nltk.corpus import stopwords\n","stop = stopwords.words('english')\n","stop.remove('what')\n","stop.remove('which')\n","print(stop)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"],"name":"stdout"}]},{"metadata":{"id":"cZRHbLvu00yb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"00efda4d-5ad3-40d6-ae18-2d9caa80dda2","executionInfo":{"status":"ok","timestamp":1552795850223,"user_tz":-330,"elapsed":1387,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('stopwords')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"GR3WrooI01aq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"b6332ee7-4e4c-4e22-8685-bd02bf87ad9a","executionInfo":{"status":"ok","timestamp":1552795858345,"user_tz":-330,"elapsed":1286,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["chatbot = pd.read_csv('chat_bot.csv',encoding='latin-1')\n","chatbot.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Questions</th>\n","      <th>Answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What are the prerequisites for this Hadoop Tra...</td>\n","      <td>There are no prerequisites for learning this c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Do I need to know anything before leaning the ...</td>\n","      <td>There are no prerequisites for learning this c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Do I need to have some programming knowledge t...</td>\n","      <td>There are no prerequisites for learning this c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Is it mandatory to know some kind of programmi...</td>\n","      <td>There are no prerequisites for learning this c...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Is programming important to learn Hadoop?</td>\n","      <td>There are no prerequisites for learning this c...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           Questions  \\\n","0  What are the prerequisites for this Hadoop Tra...   \n","1  Do I need to know anything before leaning the ...   \n","2  Do I need to have some programming knowledge t...   \n","3  Is it mandatory to know some kind of programmi...   \n","4          Is programming important to learn Hadoop?   \n","\n","                                             Answers  \n","0  There are no prerequisites for learning this c...  \n","1  There are no prerequisites for learning this c...  \n","2  There are no prerequisites for learning this c...  \n","3  There are no prerequisites for learning this c...  \n","4  There are no prerequisites for learning this c...  "]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"jhn_hCHQ07m1","colab_type":"code","colab":{}},"cell_type":"code","source":["def postag(pos):\n","  if pos.startswith('N'):\n","      wp = wordnet.NOUN\n","  elif pos.startswith('V'):\n","    wp = wordnet.VERB\n","  elif pos.startswith('R'):\n","    wp = wordnet.ADV\n","  elif pos.startswith('J'):\n","    wp = wordnet.ADJ\n","  else:\n","    wp = wordnet.NOUN\n","    \n","  return wp\n","\n","wnl = WordNetLemmatizer() # intilize wordnetlemmatizer\n","\n","def texprocess(doc):\n","\n","  # step-1: lower the text\n","  doc = doc.lower()\n","  # step-2: remove special characters\n","  doc = re.sub(r'[^a-z]',' ',doc)\n","  # step-3: pos tagging (parts of speech) \n","  token = word_tokenize(doc) # tokenization - get the words\n","  token_pos = pos_tag(token) # tagging parts of speech\n","  # step-4: stemming\n","  #ps = PorterStemmer()\n","  #stemming = [ps.stem(word) for word in token]\n","  # step-4 : lemma and remove stopwords\n","  lemma = [wnl.lemmatize(word,pos=postag(pos)) for word,pos in token_pos if word not in stop]\n","\n","  clean = \" \".join(lemma)\n","  return clean\n","\n","def cosine(a,b):\n","  moda = np.linalg.norm(a) # magnitude of a\n","  modb = np.linalg.norm(b) # magnitude of b\n","  dotprod = np.dot(a,b) # dot product of vector a and vector b\n","  # a[0] , b[0] -> remove shape in it , we don't want vector to have some shape\n","  # i.e, neither column matrix nor row matrix\n","  cos = dotprod/(moda*modb)\n","  # print('INFO: similarity between document a and b is =',cos_theta)\n","  return cos"],"execution_count":0,"outputs":[]},{"metadata":{"id":"laqoGwWS2gHk","colab_type":"text"},"cell_type":"markdown","source":["# Word Embedding\n","- Count Vectorizer\n","\n","### Ranking Documents\n","- cosine similarity\n","\n"," $cos(a,b) = \\frac{\\bar a. \\bar b}{|a||b|}$"]},{"metadata":{"id":"hK0vmDsX2_TM","colab_type":"code","colab":{}},"cell_type":"code","source":["documents = list(chatbot['Questions'])\n","# Step-1: Text processing\n","documents = [texprocess(doc) for doc in documents] # text processing of the all the documents"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qDl6YEX73ofw","colab_type":"text"},"cell_type":"markdown","source":["Step-2 : Word Embedding"]},{"metadata":{"id":"WB4NmPbR1H-2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"a013b499-2fe9-4527-fc98-76e774badb9d","executionInfo":{"status":"ok","timestamp":1552796279896,"user_tz":-330,"elapsed":1796,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer()\n","\n","X = cv.fit_transform(documents).toarray() # word embedding count vectorizer\n","print('INFO: shape of array =',X.shape)\n","print('INFO: Features list =',cv.get_feature_names())\n","print('INFO: length of features =',len(cv.get_feature_names()))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["INFO: shape of array = (726, 484)\n","INFO: Features list = ['able', 'accept', 'access', 'accredit', 'achive', 'acronym', 'actually', 'advantage', 'afternoon', 'agile', 'agility', 'ai', 'algorithm', 'amason', 'amazon', 'analysis', 'analyst', 'analytics', 'anything', 'anywahre', 'apace', 'apache', 'application', 'apply', 'approach', 'approch', 'architech', 'architect', 'article', 'artificial', 'assistance', 'associate', 'attend', 'automation', 'available', 'average', 'aws', 'back', 'background', 'backup', 'become', 'behind', 'benefit', 'benificear', 'benifits', 'best', 'big', 'bigdata', 'blog', 'blue', 'body', 'bot', 'branch', 'break', 'buesness', 'build', 'building', 'bulk', 'bye', 'call', 'cancel', 'candidate', 'capstone', 'card', 'care', 'career', 'case', 'cd', 'certifaction', 'certificate', 'certification', 'certified', 'certify', 'chalenges', 'challenge', 'chef', 'ci', 'ciao', 'class', 'classification', 'classroom', 'cleaning', 'cloud', 'cod', 'come', 'common', 'company', 'complete', 'component', 'compponents', 'comprise', 'compute', 'computer', 'concept', 'conceptual', 'conduct', 'connect', 'consider', 'contact', 'content', 'continue', 'continuo', 'continuous', 'cost', 'coureses', 'course', 'coursework', 'cover', 'credit', 'dat', 'data', 'datasets', 'day', 'degree', 'delivery', 'demand', 'demo', 'depend', 'deployment', 'desirable', 'developer', 'development', 'device', 'devopa', 'devops', 'devovps', 'devsecops', 'difference', 'different', 'differentiate', 'differnt', 'difficult', 'discount', 'docker', 'domains', 'dude', 'dvoups', 'earn', 'economics', 'effective', 'effort', 'eligibility', 'employer', 'engineer', 'enrol', 'enroll', 'enrollment', 'entail', 'environment', 'etc', 'even', 'evening', 'everyone', 'exam', 'example', 'expect', 'expectation', 'experience', 'explain', 'express', 'extention', 'extremely', 'face', 'factor', 'faculti', 'faculty', 'fail', 'fee', 'field', 'find', 'finish', 'flume', 'follow', 'form', 'framework', 'free', 'fresher', 'future', 'get', 'give', 'global', 'go', 'good', 'guarantee', 'guidance', 'hadoop', 'hand', 'happening', 'hear', 'heard', 'hello', 'help', 'helpful', 'hey', 'heyyo', 'hi', 'hire', 'history', 'hit', 'hive', 'hope', 'hot', 'hour', 'hub', 'implement', 'implementation', 'implemetation', 'implrmentation', 'important', 'improve', 'include', 'increase', 'independent', 'india', 'indusry', 'industry', 'innomatics', 'institute', 'institution', 'integration', 'intelligence', 'interview', 'involve', 'issue', 'jenkins', 'job', 'join', 'key', 'kind', 'know', 'knowledge', 'lab', 'language', 'laptop', 'lean', 'learn', 'learning', 'leave', 'less', 'license', 'like', 'listen', 'little', 'live', 'locate', 'location', 'log', 'long', 'look', 'machine', 'macro', 'macros', 'main', 'makeup', 'management', 'mandatory', 'many', 'mapreduce', 'market', 'material', 'math', 'mathematics', 'matter', 'mean', 'median', 'mention', 'methodology', 'mine', 'mining', 'miss', 'ml', 'mode', 'model', 'money', 'morning', 'much', 'must', 'name', 'near', 'necessary', 'need', 'new', 'next', 'night', 'objective', 'offer', 'office', 'one', 'online', 'open', 'opperations', 'option', 'organisation', 'organization', 'others', 'overall', 'part', 'pas', 'pass', 'past', 'path', 'pay', 'payment', 'payslip', 'pega', 'perfect', 'period', 'person', 'personal', 'perspective', 'pipeline', 'place', 'placement', 'plan', 'platform', 'podcasts', 'policy', 'popular', 'posse', 'possible', 'post', 'powerful', 'practice', 'pre', 'prediction', 'preferred', 'prepare', 'prepping', 'prerecord', 'prerequisite', 'present', 'price', 'prior', 'priority', 'prism', 'problem', 'process', 'product', 'profession', 'professional', 'program', 'programming', 'project', 'prolific', 'proper', 'prosper', 'provide', 'purpose', 'put', 'python', 'qualifications', 'rdm', 'real', 'really', 'receive', 'recommend', 'recommended', 'record', 'recruit', 'reduce', 'reduction', 'reexamination', 'reference', 'refund', 'register', 'relate', 'remote', 'replace', 'require', 'requirement', 'result', 'resume', 'retake', 'return', 'robotic', 'role', 'rpa', 'run', 'salary', 'scala', 'schedule', 'science', 'scientist', 'scope', 'script', 'scripting', 'scrum', 'security', 'see', 'select', 'selenium', 'service', 'session', 'set', 'significance', 'similar', 'simplilearn', 'skill', 'skills', 'solution', 'soon', 'source', 'spark', 'spend', 'sql', 'stage', 'stand', 'start', 'statistic', 'step', 'store', 'study', 'succeed', 'successful', 'suggest', 'suitable', 'sup', 'support', 'sure', 'syllabus', 'system', 'ta', 'take', 'taught', 'teach', 'teacher', 'teaching', 'team', 'technical', 'technique', 'technologies', 'technology', 'tell', 'testimonial', 'thing', 'think', 'time', 'tipical', 'today', 'tool', 'top', 'topic', 'train', 'trainer', 'training', 'transformation', 'type', 'typical', 'ui', 'uipath', 'unlock', 'us', 'use', 'used', 'useful', 'usefull', 'user', 'usually', 'valid', 'validation', 'valuable', 'video', 'waht', 'waive', 'waiver', 'want', 'watch', 'waterfall', 'way', 'wazzup', 'web', 'week', 'well', 'wep', 'what', 'whats', 'which', 'without', 'wonderful', 'work', 'world', 'would', 'ya', 'yes']\n","INFO: length of features = 484\n"],"name":"stdout"}]},{"metadata":{"id":"MOEexVaJ4gTb","colab_type":"text"},"cell_type":"markdown","source":["### Finding Similar documents"]},{"metadata":{"id":"hCMJJzmS6fDM","colab_type":"code","colab":{}},"cell_type":"code","source":["import operator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6Lgq7xwW2lNY","colab_type":"code","colab":{}},"cell_type":"code","source":["def chatanswers(query):\n","\n","  # step-1: text processing\n","  clean = texprocess(query)\n","  # step-2: word embedding (count vectorizer)\n","  b = cv.transform([query]).toarray() # query in list\n","\n","  cosvalue ={}\n","  for i,vector in enumerate(X):\n","    cos = cosine(vector,b[0]) # b[0] -> remove shape in it \n","    cosvalue.update({i:cos}) # append values in dictonary\n","\n","  #df['cos'] = cosvalue.values()\n","  #df.sort_values(by='cos',ascending=False)\n","  sort = sorted(cosvalue.items(), key=operator.itemgetter(1),reverse=True)\n","  ind = [index for index,cosv in sort[:5]][0]\n","  return ind,str(chatbot.loc[ind]['Answers'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-cuVq6OA4n_e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"7df2ff0c-2007-49a2-fa2f-659de90e6fb5","executionInfo":{"status":"ok","timestamp":1552797262421,"user_tz":-330,"elapsed":1666,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["query = 'what is data science ?'\n","index, ans = chatanswers(query)\n","print(ans)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in true_divide\n"],"name":"stderr"}]},{"metadata":{"id":"jlj70f5r4vAj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"7f29659d-6839-4738-f2a9-f8f593d1e97f","executionInfo":{"status":"ok","timestamp":1552797589386,"user_tz":-330,"elapsed":7094,"user":{"displayName":"sk ra","photoUrl":"","userId":"08213677811500868575"}}},"cell_type":"code","source":["while True:\n","\n","  chatinput = input('Srikanth: ')\n","  if chatinput == 'exit':\n","    print('Thank you very much have a nice day !!!')\n","    break\n","    \n","  ind, ans = chatanswers(chatinput)\n","  print(ans)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Srikanth: exit\n","Thank you very much have a nice day !!!\n"],"name":"stdout"}]},{"metadata":{"id":"O_6mQV5T5D2W","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}